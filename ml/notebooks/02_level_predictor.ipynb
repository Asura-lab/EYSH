{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f60d13ee",
   "metadata": {},
   "source": [
    "# 02. Level Predictor Model\n",
    "\n",
    "Сурагчийн түвшинг тодорхойлох модел сургах\n",
    "\n",
    "**Input features:**\n",
    "- Зөв хариултын тоо\n",
    "- Дундаж хугацаа\n",
    "- Хүнд асуултанд зөв хариулсан эсэх\n",
    "- Сэдэв тус бүрийн оноо\n",
    "\n",
    "**Output:**\n",
    "- Түвшин (1-10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fc323f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "import joblib\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f3b20c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Synthetic data үүсгэх (жинхэнэ өгөгдөл ороогүй үед)\n",
    "np.random.seed(42)\n",
    "\n",
    "n_samples = 1000\n",
    "\n",
    "# Features\n",
    "data = {\n",
    "    'correct_ratio': np.random.uniform(0.1, 1.0, n_samples),\n",
    "    'avg_time_seconds': np.random.uniform(30, 300, n_samples),\n",
    "    'hard_questions_correct': np.random.uniform(0, 1, n_samples),\n",
    "    'math_score': np.random.uniform(0, 100, n_samples),\n",
    "    'physics_score': np.random.uniform(0, 100, n_samples),\n",
    "    'chemistry_score': np.random.uniform(0, 100, n_samples),\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Create target (level 1-10)\n",
    "# Based on weighted combination\n",
    "weighted_score = (\n",
    "    df['correct_ratio'] * 40 +\n",
    "    df['hard_questions_correct'] * 30 +\n",
    "    (df['math_score'] + df['physics_score'] + df['chemistry_score']) / 3 * 0.3\n",
    ")\n",
    "\n",
    "# Add some noise\n",
    "weighted_score += np.random.normal(0, 5, n_samples)\n",
    "\n",
    "# Convert to levels 1-10\n",
    "df['level'] = pd.cut(weighted_score, bins=10, labels=range(1, 11)).astype(int)\n",
    "\n",
    "print(df.head())\n",
    "print(f'\\nLevel distribution:\\n{df[\"level\"].value_counts().sort_index()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c25c5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train/Test split\n",
    "X = df.drop('level', axis=1)\n",
    "y = df['level']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "print(f'Train size: {len(X_train)}')\n",
    "print(f'Test size: {len(X_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e175a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train multiple models\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBClassifier(n_estimators=100, random_state=42, use_label_encoder=False, eval_metric='mlogloss')\n",
    "}\n",
    "\n",
    "results = {}\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f'\\n--- {name} ---')\n",
    "    \n",
    "    # Cross-validation\n",
    "    cv_scores = cross_val_score(model, X_train_scaled, y_train, cv=5)\n",
    "    print(f'CV Score: {cv_scores.mean():.4f} (+/- {cv_scores.std():.4f})')\n",
    "    \n",
    "    # Train\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    # Test\n",
    "    test_score = model.score(X_test_scaled, y_test)\n",
    "    print(f'Test Score: {test_score:.4f}')\n",
    "    \n",
    "    results[name] = {'cv_score': cv_scores.mean(), 'test_score': test_score, 'model': model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be112fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best model selection\n",
    "best_model_name = max(results, key=lambda x: results[x]['test_score'])\n",
    "best_model = results[best_model_name]['model']\n",
    "\n",
    "print(f'Best Model: {best_model_name}')\n",
    "\n",
    "# Detailed evaluation\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "print('\\nClassification Report:')\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9eee384",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "if hasattr(best_model, 'feature_importances_'):\n",
    "    importance = pd.DataFrame({\n",
    "        'feature': X.columns,\n",
    "        'importance': best_model.feature_importances_\n",
    "    }).sort_values('importance', ascending=False)\n",
    "    \n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(data=importance, x='importance', y='feature')\n",
    "    plt.title('Feature Importance')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18f49343",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model\n",
    "model_data = {\n",
    "    'model': best_model,\n",
    "    'scaler': scaler,\n",
    "    'features': list(X.columns)\n",
    "}\n",
    "\n",
    "joblib.dump(model_data, '../trained_models/level_predictor.pkl')\n",
    "print('Model saved to: ../trained_models/level_predictor.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e9dd6de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test loading\n",
    "loaded = joblib.load('../trained_models/level_predictor.pkl')\n",
    "\n",
    "# Predict on new data\n",
    "sample = {\n",
    "    'correct_ratio': 0.75,\n",
    "    'avg_time_seconds': 120,\n",
    "    'hard_questions_correct': 0.6,\n",
    "    'math_score': 80,\n",
    "    'physics_score': 70,\n",
    "    'chemistry_score': 75\n",
    "}\n",
    "\n",
    "sample_df = pd.DataFrame([sample])\n",
    "sample_scaled = loaded['scaler'].transform(sample_df)\n",
    "prediction = loaded['model'].predict(sample_scaled)\n",
    "\n",
    "print(f'Sample prediction: Level {prediction[0]}')"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
